{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_folder = './commands/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "command_labels = ['bongeszo', 'fazok', 'homerseklet_alap','homerseklet_vissza','klima_be','klima_le','melegem_van','mennyi_az_ido','vicc','villany_fel','villany_le' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(command_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_log_mel_spectrogram(file_path,n_mels=128,  duration=4.0):\n",
    "    # Load the audio file\n",
    "    \n",
    "    waveform, sr = librosa.load(file_path, duration=duration)\n",
    "    hop_length = int(sr * (0.02 - 0.01))\n",
    "    # Extract the Log-Mel-spectrogram\n",
    "    mel_spectrogram = librosa.feature.melspectrogram(waveform, sr=sr, n_mels=n_mels, hop_length=hop_length)\n",
    "    log_mel_spectrogram = librosa.amplitude_to_db(mel_spectrogram, ref=np.max)\n",
    "\n",
    "    return log_mel_spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_shape=(128, 401, 1) input_shape=(n_mels, hop_length, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "for label_idx, label in enumerate(command_labels):\n",
    "    command_folder = os.path.join(root_folder, label)\n",
    "    files = os.listdir(command_folder)\n",
    "\n",
    "    # Loop through the audio files in each command folder\n",
    "    for file in files:\n",
    "        file_path = os.path.join(command_folder, file)\n",
    "\n",
    "        # Load and preprocess the Log-Mel-spectrogram (replace with your own preprocessing steps)\n",
    "        mel_spectrogram = preprocess_log_mel_spectrogram(file_path)\n",
    "\n",
    "        # Append the features and labels\n",
    "        features.append(mel_spectrogram)\n",
    "        labels.append(label_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(features[0][0]))\n",
    "print(len(features[1000][0]))\n",
    "print(len(features[6000][0]))\n",
    "print(len(features[9000][0]))\n",
    "print(len(features[10000][0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_shape = max(feature.shape for feature in features)\n",
    "\n",
    "# Create a new list to store the padded Log-Mel-spectrograms\n",
    "padded_features = []\n",
    "ff = 0\n",
    "# Pad the Log-Mel-spectrograms to match the maximum shape\n",
    "for feature in features:\n",
    "    pad_width = [(0, max_shape[0] - feature.shape[0]), (0, max_shape[1] - feature.shape[1])]\n",
    "    ff = pad_width\n",
    "    padded_feature = np.pad(feature, pad_width, mode='constant')\n",
    "    padded_features.append(padded_feature)\n",
    "\n",
    "# Convert the padded features to a NumPy array\n",
    "features = np.array(padded_features)\n",
    "labels = np.array(labels)\n",
    "\n",
    "train_features, val_features, train_labels, val_labels = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print the shapes of the training and validation sets\n",
    "print(\"Training features shape:\", train_features.shape)\n",
    "print(\"Training labels shape:\", train_labels.shape)\n",
    "print(\"Validation features shape:\", val_features.shape)\n",
    "print(\"Validation labels shape:\", val_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Convert the features and labels to NumPy arrays\n",
    "features = np.array(features)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "train_features, val_features, train_labels, val_labels = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print the shapes of the training and validation sets\n",
    "print(\"Training features shape:\", train_features.shape)\n",
    "print(\"Training labels shape:\", train_labels.shape)\n",
    "print(\"Validation features shape:\", val_features.shape)\n",
    "print(\"Validation labels shape:\", val_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, LSTM, Dense, Dropout, Flatten, TimeDistributed\n",
    " \n",
    "model = Sequential()\n",
    "\n",
    "    # CNN layers\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(128, 401, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "    # LSTM layers\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "model.add(LSTM(64, recurrent_dropout=0.1,return_sequences=False))\n",
    "\n",
    "    # Fully connected layers\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(11, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "    # CNN layers\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(128, 401, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "    # Fully connected layers\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(11, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# tf.config.experimental_run_functions_eagerly(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "loss_function = tf.keras.losses.CategoricalCrossentropy()\n",
    "metrics = [tf.keras.metrics.CategoricalAccuracy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = to_categorical(train_labels, num_classes=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 20\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "loss_function = tf.keras.losses.CategoricalCrossentropy()\n",
    "metrics = [tf.keras.metrics.CategoricalAccuracy()]\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=metrics)\n",
    "\n",
    "model.fit(train_features, train_labels, batch_size=batch_size, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"convloss05catacc98.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.saved_model.save(model, \"./saved_trained_models/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('./convloss05catacc98.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "spec_to_predict = preprocess_log_mel_spectrogram('./test_voices/lekgondi_le2.wav')\n",
    "spec_to_predict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A modell elvárt input shape-je\n",
    "desired_shape = model.input_shape\n",
    "\n",
    "# Kiszámítjuk a szükséges padding-et az első két dimenzióra\n",
    "pad_width = [(0, desired_shape[1] - spec_to_predict.shape[0]),\n",
    "             (0, desired_shape[2] - spec_to_predict.shape[1])]\n",
    "\n",
    "# Padding-et alkalmazunk a spektrogramra\n",
    "padded_spec = np.pad(spec_to_predict, pad_width, mode='constant')\n",
    "\n",
    "# Az eredmény shape-je már megfelel a modell elvárt input shape-jének\n",
    "print(padded_spec.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_to_predict = np.expand_dims(padded_spec, axis=-1)\n",
    "print(spec_to_predict.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_to_predict_batch = np.expand_dims(spec_to_predict, axis=0)\n",
    "print(spec_to_predict_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(spec_to_predict_batch)\n",
    "\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_class_index = np.argmax(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_class = command_labels[predicted_class_index]\n",
    "print(predicted_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "waveformp, srp = librosa.load('./test_voices/hom_alap.wav', duration=4.0)\n",
    "hop_length = int(srp * (4.0 / 588.0))\n",
    "print(hop_length)\n",
    "    # Extract the Log-Mel-spectrogram\n",
    "mel_spectrogramPRE = librosa.feature.melspectrogram(waveformp, sr=srp, n_mels=128, hop_length=149)\n",
    "log_mel_spectrogramPRE = librosa.amplitude_to_db(mel_spectrogramPRE, ref=np.max)\n",
    "\n",
    "log_mel_spectrogramPRE = log_mel_spectrogramPRE.reshape(1, log_mel_spectrogramPRE.shape[0], log_mel_spectrogramPRE.shape[1], 1)\n",
    "\n",
    "predictions = model.predict(log_mel_spectrogramPRE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_mel_spectrogramPRE.shape[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_mel_spectrogramPRE = log_mel_spectrogramPRE.reshape(1, log_mel_spectrogramPRE.shape[0], log_mel_spectrogramPRE.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gg = np.pad(log_mel_spectrogramPRE, ff, mode='constant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(log_mel_spectrogramPRE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
